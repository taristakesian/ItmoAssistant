# README

## 0) Предисловие

*Ранее я разрабатывал схожие решения, успешно отработавшие в проде — этот опыт я перенёс в текущий проект. Из ассистента автодополнения для системных аналитиков я использовал RAG-архитектуру. Из QA-ассистента для сайта копицентра — практики борьбы с галлюцинациями.*

## 1) Архитектура

### Компоненты и поток данных
```
[ Страницы ИТМО + внешние сайты программ ]
           │
           ▼
   parser_pipeline.py
   ├─ поиск ссылок на учебные планы (в т.ч. Google Drive)
   ├─ скачивание PDF/HTML
   ├─ извлечение текста и таблиц (pdfplumber + эвристики)
   ├─ нормализация → data/normalized/curriculum.csv
   └─ метаданные → data/program_meta/<slug>.json
           │
           ▼
        rag_openai.py
   ├─ сбор документов (CSV/JSON/тексты)
   ├─ эмбеддинги: OpenAI text-embedding-3-small
   ├─ векторное хранилище: Chroma (persist)
   └─ формирование ответа (RAG) с LLM
           │
           ▼
           bot.py (aiogram)
```

### Ключевые файлы
- `parser_pipeline.py` — единый парсер/нормализатор/сборщик метаданных.
- `rag_openai.py` — индексация и RAG.
- `bot.py` — Telegram-бот на `aiogram`.
- `main.py` — единая точка запуска: `parse`, `index`, `bot`, `up`.
- `data/` — артефакты: `raw/`, `processed/`, `normalized/`, `program_meta/`, `index/`.

---

## 2) Обоснование архитектуры

- **Использование API.** Использована именно API решение, а не локальное, чтобы убрать требование на наличие GPU, + решение было легко запустить без лишних скачиваний тяжёлых моделей.
- **Chroma + OpenAI Embeddings.** Локальная база, быстрый поиск, простая интеграция с LangChain. Эмбеддинги `text-embedding-3-small` оптимальны по цене/качеству для RU/EN.
- **OpenAI gpt-5-nano.** Использован в качестве LLM `gpt-5-nano` - оптимальна по цене/качеству для RU/EN.
- **Анти-галлюцинации на двух уровнях.** Жёсткий системный промпт, чтобы модель не фантазировала.

- **RAG**: берём документную базу (учебные планы, мета-данные), считаем эмбеддинги, ищем релевантные фрагменты в Chroma, и только их отдаём в LLM — модель отвечает по фактам из контекста. Такая архитектура позволяет легко найти релевантный контекст для модели.

---

## 3) Кратко: как устроен парсинг

1. **Поиск источников**
   - Старт со страниц: `abit.itmo.ru/program/master/ai` и `.../ai_product`.
   - Поиск ссылок на планы: якоря «Учебный план», прямые PDF `itmo.ru/file_storage/...`, ссылки `drive.google.com` (включая `script` и data-атрибуты).
   - Дополнительно — внешние сайты программ (`ai.itmo.ru`, `aiproduct.itmo.ru`) для раздела «Команда/эксперты» (на `abit` блок часто грузится через JS).

2. **Скачивание и извлечение**
   - Качаем PDF (в т.ч. через `uc?export=download` для Google Drive).
   - Извлекаем текст постранично (для отладки помечаем `--- PAGE N ---`).
   - Таблицы: сначала стратегия по линиям; если не сработала — резервный режим: разбиение строк по 2+ пробелам/табам и выравнивание ширины.

3. **Нормализация учебных планов**
   - Фильтрация «шапок» («Обязательные дисциплины», «Пул выборных…», «Soft Skills…»).
   - Распознавание семестров: `1`, `1, 2, 3`, и формы «… 2 семестр» внутри названия.
   - Результат: `data/normalized/curriculum.csv` — поля `program, semester, course, type, credits, hours, source_pdf`.

4. **Метаданные программ**
   - `data/program_meta/<slug>.json`: описание, контакты, соцсети, ссылки на планы/стоимость, менеджер (ФИО/почта/телефон), команда/преподаватели (с внешних сайтов).

---

## 4) Как обходим галлюцинации

- **Системный промпт (политика ответов)**
  - Отвечать только по магистерским программам ИТМО «AI» и «AI Product».
  - Использовать только факты из переданного контекста.
  - Если вопрос про другой вуз (ВШЭ/HSE, МФТИ, СПбГУ и т.п.) — фиксированный отказ.
  - Если релевантного контекста нет — фиксированный отказ.
  - Запрещены конструкции «вероятно/возможно/скорее всего/обычно».

- **Настройки генерации**
  - короткий формат ответа.

---

## 5) Какие источники использовали для составления архитектуры

- **Документация библиотек**
  - `pdfplumber`, `BeautifulSoup`/`lxml`, `requests`, `pandas`
  - `langchain-openai`, `langchain-chroma`, `langchain-community`, `chromadb`
  - `aiogram v3`

- **Практические наработки**
  - Обсуждения и разбор альтернатив с помощью ChatGPT (архитектура RAG, анти-галлюцинации, диагностика ошибок, выбор инструментов).
